---
title: "NFL Losers Pool 2021 Exploration"
author: "Jordan Hutchings"
date: "08/09/2021"
output: 
  html_document:
    keep_md: true
---


```{r, echo = FALSE}
knitr::opts_chunk$set(
  fig.path = "README_figs/README-"
)
```

Our annual NFL losers pool runs by each entrant having to pick one team per week. 
The objective is to pick one team to lose each week, if your team wins, you are 
out of the pool. The catch is that once a team is picked it cannot be picked 
again. 

I am taking a fairly simple approach to making my picks this year. 
Download and use the NFL forecast data from 
[FiveThirtyEight](https://projects.fivethirtyeight.com/2021-nfl-predictions/games/) 
to optimize my picks to give the best probability of lasting deep into the season. 

```{r, echo = FALSE}

#TODO: Update the code to handle future weeks.

source("pick_functions.R")
pacman::p_load(data.table, ggplot2, ggalt, dplyr, knitr, kableExtra)

# Setup ---- 
path <- "https://projects.fivethirtyeight.com/nfl-api/nfl_elo_latest.csv"
week1 <- as.Date("2021-09-09")
total_weeks <- 10
start_week <- max(ceiling(as.numeric(( Sys.Date() - as.Date("2021-09-09") )) / 7) + 1, 3) # little janky
time_period <- c(start_week:total_weeks)
past_picks <- c("DAL", "TEN", "NYJ", "HOU", "MIA") # alternate with CHI, and DAL
past_weeks <- c(1, 2, 3, 4, 5)

dt <- read_data(path, all_weeks = FALSE)
```

## Visualizations 
Below we can see a heatmap of all the win probabilities throughout the season. 
Teams like Houston, and Washington have a low likelihood of winning in many 
games in the season. This motivates our problem as we can only pick them each 
once. The teams are ordered by average likelihood of winning, we can see Houston, 
Detroit, and Jacksonville are the three lowest teams. There is an opportunity to 
out play my competitors by picking these teams in the best possible week, i.e. 
holding off until Week 4 to pick Houston.

```{r, echo = FALSE}
plot_data <- read_data(path, all_weeks = TRUE)

# sort teams by average win prob
plot_data %>% 
  tidyr::pivot_longer(cols = c("loser", "winner"), values_to = "team") %>%
  mutate(p = ifelse(name == "loser", p_win, p_win_winner)) %>%
  select(-c("p_win", "p_win_winner")) %>%
  group_by(team) %>%
  mutate(win_avg = mean(p)) %>%
  ungroup() %>%
  mutate(team = reorder(team, win_avg)) %>% # reorder teams by avg win
  ggplot(aes(week, team, fill=p)) + 
  geom_tile() + 
  scale_fill_viridis_c("Pr(Win)") + 
  theme_classic() + 
  labs(title = "Weekly Win Probabilities Heatmap by team", 
       x = "Week Number", 
       y = "Team Name") + 
  scale_x_continuous(expand = c(0, 0))
```

Below is a plot of the choice set of underdogs in each game. We can see there 
is a finite set of picks per week, with each week having differing probabilities. 
Ideally, we are looking for the path through these points that minimizes our 
chances of losing from the competition.

```{r, echo = FALSE}
ggplot(data = plot_data, aes(x=week, y=p_win)) + 
  geom_point(alpha=0.8, color="gray", size = 3) + 
  # geom_line(aes(group = loser), alpha = 0.2) + # use this to show some pick profiles
  coord_flip() + 
  labs(title = "Candidate picks per week", 
       x = "Week Number", 
       y = "Win Probability") + 
  theme_classic(12)
```

## Different approaches to consider

Below I compare two naive strategies with a more rigorous approach. 
We begin in Week 3, as Weeks 1 and 2 are rebuy weeks. These picks are made 
picking the lowest probability remaining after removing weeks 3 - 10.

Approaches:  
1. Pick the lowest team by week, starting in the first week.  
2. Pick the lowest win probability across all weeks.  
3. Pick the team-week pairing with the greatest opportunity cost. In other words, 
if the team isn't picked, how much of a percentage is given up. 

Each of the above approaches allow for future discounting. I.e. 
$$ Pr(Win | Week = w) = Pr(Win) * \beta^{(w - \underline{w})}$$ where 
$\underline{w}$ is the start week. 

The table below shows the optimal picks following each approach, past weeks are 
filled with the set picks I made. We can see there is a slight improvement when 
moving from the naiive approaches to Approach 3.

```{r, echo = FALSE}
wk <- by_week(past_picks, past_weeks, beta = 1, start_week = start_week, total_weeks = total_weeks)
pr <- by_prob(past_picks, past_weeks, beta = 1, start_week = start_week, total_weeks = total_weeks)
oc <- by_oc(past_picks, past_weeks, beta = 1, start_week = start_week, total_weeks = total_weeks)

tbl <- left_join(wk, pr, by="week")
tbl <- left_join(tbl, oc, by="week")
names <- c("Week", rep(c("Team", "ProbWin"), 3))
names(tbl) <- names

avg_1 <- mean(as.numeric(wk$p_win))
avg_2 <- mean(as.numeric(pr$p_win))
avg_3 <- mean(as.numeric(oc$p_win))
avg_row <- data.frame("Mean", "", avg_1, "", avg_2, "", avg_3)
names(avg_row) <- names(tbl)


sd_1 <- sd(as.numeric(wk$p_win))
sd_2 <- sd(as.numeric(pr$p_win))
sd_3 <- sd(as.numeric(oc$p_win))
sd_row <- data.frame("SD", "", sd_1, "", sd_2, "", sd_3)
names(sd_row) <- names(tbl)


tbl <- rbind(tbl, avg_row)
tbl <- rbind(tbl, sd_row)

kbl(tbl, digits=3, caption = "Comparison of approaches") %>%
  kable_classic(full_width=F) %>%
  add_header_above(c(" " = 1, "Approach 1" = 2, "Approach 2" = 2, "Approach 3" = 2)) %>%
  row_spec(nrow(tbl), bold=T) %>%
  row_spec(nrow(tbl) - 1, bold=T)
```
## Discounting future games

We have been working off a $\beta = 1$ for each model. Below are the changes 
from using different values of $\beta$. Future discounting will place a higher 
weight on upcoming weeks. This will not change the By Week model but will 
have an impact on the By Probability and By Oppertunity Cost. The overall average 
probability of winning a game will increase as we are discounting future games. 
What matters now though is how much more probability we are shifting away from 
future weeks and to upcoming weeks. Therefore, we should no longer evaluate 
from the average risk per week, and instead the likelihood of reaching a given week. 

## Calculating probability of making a given week

Since the game outcomes are binary 
we can also calculate the proportion of times we reach a given week 
as the following, recall $Pr(w_i)$ is the probability of the pick winning 
in week $i$, or losing in week $i$.

$$ Pr(W \leq w) = \Pi_{i = 1}^w (1 - Pr(w_i))  $$

```{r, echo = FALSE}
cumprob <- function(picks, inc_weeks = FALSE){
  p <- purrr::accumulate((1-picks$p_win), function(x, y)  x * y)
  weeks <- picks$Week
  
  
  if(inc_weeks){
    out <- data.frame(p, weeks)
  } else {
    out <- data.frame(p)
  }
  
  out
}

oc9 <- by_oc(past_picks, past_weeks, beta = 0.9)
oc7 <- by_oc(past_picks, past_weeks, beta = 0.7)
pr9 <- by_prob(past_picks, past_weeks, beta = 0.9)
pr7 <- by_prob(past_picks, past_weeks, beta = 0.7)

results <- list()
models <- list(oc, oc9, oc7, pr, pr9, pr7, wk)
results <- lapply(models, function(x) cumprob(x))

results <- do.call(cbind.data.frame, results)
names(results) <- c("Opp Cost, Beta = 1", "Opp Cost, Beta = 0.9", "Opp Cost, Beta = 0.7", 
                    "By Prob, Beta = 1", "By Prob, Beta = 0.9", "By Prob, Beta = 0,7", 
                    "By Week")
results$Week <- seq(start_week, 10, 1)

results %>%
  tidyr::pivot_longer(cols = -Week, names_to = "Model", values_to = "p") %>%
  ggplot(aes(x = Week, y = p, color = Model)) +
  geom_line() + 
  geom_point(alpha = 0.8) + 
  scale_x_continuous(expand = c(0, 0), limits = c(start_week, 10)) +
  scale_y_continuous(expand = c(0, 0), limits = c(0, 1)) + 
  labs(title = "Probability of reaching a given week",
       x = "Week number", 
       y = "Pr(W < w)") + 
  theme_classic(10)

results <- select(results, Week, everything()) # hack to reorder cols.

kbl(results, digits = 2, caption = "Likelihood of reaching a given week by model") %>%
  kable_classic(full_width=F) %>%
  footnote(general = "Percentages represent the likelihood of reaching a given 
           week based on the picks from each model.")
           
```

As expected, we have better chances earlier when using a discount value less than 
one for the Opportunity Cost model. Notice there is not much variation across 
differing beta values. 

```{r, echo = FALSE}

# Consider merge...
# figure out dup col names and good to go.
# data <- Reduce(function(...) merge(..., by = c("week"), all.x = TRUE, suffix = c(seq(1, 7, 1))), 
#                list(oc, oc9, oc7, wk, pr, pr9, pr7))

models <- list(oc, oc9, oc7, wk)
tbl <- Reduce(function(...) merge(..., by = c("week"), all.x = TRUE), models)

names <- c("Week", rep(c("Team", "ProbWin"), 4))
names(tbl) <- names

avg_1 <- mean(as.numeric(oc$p_win))
avg_2 <- mean(as.numeric(oc9$p_win))
avg_3 <- mean(as.numeric(oc7$p_win))
avg_4 <- mean(as.numeric(wk$p_win))

avg_row <- data.frame("Mean", "", avg_1, "", avg_2, "", avg_3, "", avg_4)
names(avg_row) <- names(tbl)

sd_1 <- sd(as.numeric(oc$p_win))
sd_2 <- sd(as.numeric(oc9$p_win))
sd_3 <- sd(as.numeric(oc7$p_win))
sd_4 <- sd(as.numeric(wk$p_win))

sd_row <- data.frame("SD", "", sd_1, "", sd_2, "", sd_3, "", sd_4)
names(sd_row) <- names(tbl)


tbl <- rbind(tbl, avg_row, sd_row)

kbl(tbl, digits=3, caption = "Weekly Picks by Model") %>%
  kable_classic(full_width=F) %>%
  add_header_above(c(" " = 1, "OC, Beta = 1" = 2, "OC, Beta = 0.9" = 2,
                     "OC, Beta = 0.7" = 2, "By Week" = 2)) %>%
  row_spec(nrow(tbl), bold=T) %>%
  row_spec(nrow(tbl) - 1, bold=T)
```

We see now a $\beta = 0.7$ gets us back to our best pick per week approach, and 
it is the $\beta = 0.9$ that may be the better option. Where we trade off total 
average for a better liklihood of lasting in the event. 

## Dumbbell plot 

Our best two models are the $OC, Beta = 1$ and $OC, Beta = 0.9$. Below are the 
differences in the picks. 

```{r, echo = FALSE}
labs <- c("Week", "Team", "ProbWin")
names(oc) <- labs
names(oc7) <- labs
names(oc9) <- labs
names(wk) <- labs
names(pr) <- labs
names(pr9) <- labs


oc$Approach <- "OC, Beta = 1"
oc7$Approach <- "OC, Beta = 0.7"
oc9$Approach <- "OC, Beta = 0.9"
wk$Approach <- "By Week"
pr$Approach <- "By Prob, Beta = 1"
pr9$Approach <- "By Prob, Beta = 0.9"



data <- rbind(oc, oc9, oc7, wk, pr, pr9)
data$Approach <- as.factor(data$Approach)


theme_set(theme_bw(12))

ggplot(data, aes(x=Week, y=ProbWin, color = Approach, shape = Approach)) + 
  geom_line(aes(group = Week), color="#e3e2e1", size = 2) +
  geom_point(size = 3) + 
  xlim(4, 10) +
  coord_flip() + 
  scale_color_viridis_d() + 
  labs(title = "Comparing weekly win probabilities per Approach", 
       x = "Week Number", 
       y = "Win Probability") + 
  theme_classic(12)
```

## Alterative weeks for optimal team picks
We can view other weeks of the recommended team below in a selection plot. 
Here the only alternative to picking HOU comes in the By Prob, Beta = 0.7 model 
which selects PIT. However, it is clear there is no future gain from this pick.

```{r, echo = FALSE}
#TODO: maybe look to other possibilities - like second best pick from the models. 
# this may be mroe complicated and require its own code block. 
dt %>% 
  filter(!week %in% past_weeks, 
         !loser %in% past_picks) %>%
  group_by(week, loser) %>%
  mutate(suggested = ifelse(loser == oc9[1, "Team"] | loser == pr7[1, "loser"] , loser, "The rest")) %>%
  ggplot() + 
  geom_point(aes(x=week, y=p_win, color = suggested), alpha=0.6, size = 3) + 
  coord_flip() + 
  labs(title = "Top two recomendations by week", 
       x = "Week Number", 
       y = "Win Probability", 
       color = "Recommended pick") + 
  scale_color_viridis_d() + 
  theme_classic(12)
```

## What is the next best possible pick?
If we remove the optimal pick from our choice set, what is the next best pick?
This is done so I can consider picking two different teams per week to hedge my 
bets. 

```{r, echo = FALSE}
first_pick <- oc9
skip <- as.character(first_pick[1,2])
beta = 0.9

# TODO: was unable to alter the original function
for(i in start_week:total_weeks){
    
    pick <- dt[week %in% c(start_week:total_weeks)]
    pick <- pick[!week %in% past_weeks & !loser %in% past_picks, ]
    if(!is.null(skip)){
      pick <- pick[!week == start_week | !loser == skip]
    }
    pick <- pick[order(week, p_win)]
    pick[, oc:= shift(p_win, 1, type="lead") - p_win, by = week]
    pick[, oc:= oc * beta^(week - start_week)]
    pick <- pick[, .SD[1], week]
    pick <- pick[order(-oc)]
    pick <- pick[, .SD[1]]
    
    past_weeks <- append(past_weeks, pick$week)
    past_picks <- append(past_picks, pick$loser)
    
  }
  
second_pick <- join_picks(past_weeks, past_picks)

# plot dumbell chart of the two
first_pick$Approach <- "First pick"
second_pick$Approach <- "Second pick"

names(first_pick) <- c("week", "loser", "p_win", "Approach")
data <- rbind(first_pick, second_pick)
ggplot(data, aes(x=week, y=p_win, color = Approach)) + 
  geom_line(aes(group = week), color="#e3e2e1", size = 2) +
  geom_point(alpha=0.6, size = 3) +
  coord_flip() + 
  labs(title = "Choice profiles when making different picks in the upcoming week", 
       x = "Week Number", 
       y = "Win Probability", 
       color = "Models") + 
  scale_color_viridis_d() + 
  theme_classic(12)

# make weekly probabilities for top pick and not top pick
prob1 <- cumprob(first_pick)
prob2 <- cumprob(second_pick)
plot <- cbind(rep(c(start_week:total_weeks), 2), prob1, prob2)
names(plot) <- c("Week", "First Pick", "Second Pick")

plot %>%
  tidyr::pivot_longer(cols = -Week, names_to = "Model", values_to = "p") %>%
  ggplot(aes(x = Week, y = p, color = Model)) +
  geom_line() + 
  geom_point(alpha = 0.8) + 
  scale_x_continuous(expand = c(0, 0), limits = c(start_week, 10)) +
  scale_y_continuous(expand = c(0, 0), limits = c(0, 1)) + 
  labs(title = "Probability of reaching a given week with and without making optimal pick next week",
       x = "Week number", 
       y = "Pr(W < w)",
       color = "Models") + 
  theme_classic(10)

# make table
tbl <- cbind(first_pick[, 1:3], second_pick[, 2:3])
avg_second <- mean(as.numeric(second_pick$p_win))
sd_second <- sd(as.numeric(second_pick$p_win))

avg_row <- data.frame("Mean", "", avg_2, "", avg_second)
sd_row <- data.frame("SD", "", sd_2, "", sd_second)
names(avg_row) <- names(tbl)
names(sd_row) <- names(tbl)
tbl <- rbind(tbl, avg_row, sd_row)
names(tbl) <- c("Week", "Pick", "ProbWin", "Pick", "ProbWin")

kbl(tbl, digits=3, caption = "Recommended sets of picks") %>%
  kable_classic(full_width=F) %>%
  add_header_above(c(" " = 1, "Optimal Pick" = 2, "Next Best" = 2)) %>%
  row_spec(nrow(tbl), bold=T) %>%
  row_spec(nrow(tbl) - 1, bold=T)
```


### Showing pick profiles on choice set
```{r, echo = FALSE}
past <- data.frame(week = past_weeks, loser = past_picks)
past <- subset(past, week < start_week)
past$Approach <- "First Pick"
first_pick <- plyr::rbind.fill(first_pick, past)
second_pick <- plyr::rbind.fill(second_pick, past)

plot_data %>%
  filter(week <= total_weeks) %>%
  left_join(first_pick, by = c("week", "loser"), suffix = c("", "_1")) %>%
  left_join(second_pick, by = c("week", "loser"), suffix = c("", "_2")) %>%
  mutate(pick1 = ifelse(is.na(Approach), "", "First Pick"), 
         pick2 = ifelse(is.na(Approach_2), "", "Second Pick")) %>%
  ggplot(aes(x=week, y=p_win)) + 
  geom_line(aes(group = pick1, color = pick1), linetype = "dashed", alpha = 0.7) +
  geom_line(aes(group = pick2, color = pick2), linetype = "dashed", alpha = 0.7) + 
  geom_point(alpha=0.8, size = 3, color = "grey") + 
  scale_color_manual(values=c("#FFFFFF", "royalblue", "forestgreen")) +
  coord_flip() + 
  labs(title = "Candidate picks per week", 
       x = "Week Number", 
       y = "Win Probability",
       color = "Pick Profiles") + 
  theme_classic(12)
```
The above analysis is not very supportive of not taking MIA in both picks next week. 
This analysis is flawed, as we rule out the first pick in each week. 

## Todos
* Make the choice plot with paths of optimal picks include picks from first N weeks.
* Make two sets of past picks for each stream of picks


## Looking back at ELO's performance
This section is a look back at the first 5 weeks of NFL projections. I am curious how 
well the forecasts are performing, and plan to plot the estimated win rate against the 
actual bserved win rate. In order to do this, I will be bucketing the probabilities into 
N discrete groups, then comuting the win percentage per group. Ideally plotting the 
forecast win rate against actual win rates should provide a 45 degree line. 

```{r}
# get data for all weeks
dt <- data.table::fread(path)
dt[, loser:=ifelse(qbelo_prob1 > qbelo_prob2, team2, team1)]
dt[, winner:=ifelse(qbelo_prob1 > qbelo_prob2, team1, team2)]
dt[, loser_score:=ifelse(qbelo_prob1 > qbelo_prob2, score2, score1)]
dt[, winner_score:=ifelse(qbelo_prob1 > qbelo_prob2, score1, score2)]
dt[, p_win:=ifelse(qbelo_prob1 > qbelo_prob2, qbelo_prob2, qbelo_prob1)]
dt[, p_win_winner:=ifelse(qbelo_prob1 > qbelo_prob2, qbelo_prob1, qbelo_prob2)]
dt[, week:=floor(as.numeric(difftime(date, week1, units="days")) / 7) + 1]
dt <- dt[!is.na(winner_score), ]
dt[, win:= as.numeric(winner_score > loser_score)]
dt[, win_bucket:= round(p_win_winner, 1)]
dt <- dt[, .(win, win_bucket)]

dt %>%
  group_by(win_bucket) %>%
  summarize(p = mean(win), 
            n = n()) %>%
  ggplot(aes(x = win_bucket, y = p)) + 
  geom_point() + 
  geom_abline(slope = 1, linetype = "dotted") + 
  xlim(0, 1) + 
  ylim(0, 1) + 
  labs(title = "Weeks 1 - 5, actual versus observed outcomes", 
       x = "Forecasted win rate", 
       y = "Observed win rate") + 
  theme_bw()
```

### repeat on historical data

```{r}
hist_data <- "https://projects.fivethirtyeight.com/nfl-api/nfl_elo.csv"
hdt <- fread(hist_data)

hdt %>%
  group_by(season) %>%
  summarise(sum(is.na(qbelo_prob1))) # begins in 1950

# clean data 
hdt[, loser:=ifelse(qbelo_prob1 > qbelo_prob2, team2, team1)]
hdt[, winner:=ifelse(qbelo_prob1 > qbelo_prob2, team1, team2)]
hdt[, loser_score:=ifelse(qbelo_prob1 > qbelo_prob2, score2, score1)]
hdt[, winner_score:=ifelse(qbelo_prob1 > qbelo_prob2, score1, score2)]
hdt[, p_win:=ifelse(qbelo_prob1 > qbelo_prob2, qbelo_prob2, qbelo_prob1)]
hdt[, p_win_winner:=ifelse(qbelo_prob1 > qbelo_prob2, qbelo_prob1, qbelo_prob2)]
hdt <- hdt[!is.na(winner_score), ]
hdt[, win:= as.numeric(winner_score > loser_score)]
hdt[, win_bucket:= round(p_win_winner, 1)]

hdt <- hdt[, .(win, win_bucket, season)]

hdt %>%
  # filter(season >= 2000) %>%
  group_by(win_bucket) %>%
  summarise(p = mean(win), n = n(), se = sd(win)) %>%
  ggplot(aes(x = win_bucket, y = p)) + 
  geom_errorbar(aes(x = win_bucket, ymin = p - 1.65*se, ymax = p + 1.65*se)) + 
  geom_point() + 
  geom_abline(slope = 1) + 
  labs(title = "Historical game - favourite win rates", 
       x = "Forecasted win rate", 
       y = "Observed win rate") + 
  theme_bw()

```
